# Realizing the Forbidden West: Translating Gameplay into Hyper-Realistic Action Shots

## This is a project done while participating in exploreCSR: Socially-Responsible AI for Computational Creativity, a semester-long immersive research experience program for undergraduate students offered by Google and Brown University.

### We present "Realizing the Forbidden West: Translating Gameplay into Hyper-Realistic Action Shots", an image-to-image translation model aimed to transform fantastical video game imagery into hyper-realistic images. Using the Pytorch CycleGAN model (Zhu et al.), we train on approximately 830 images each from the 'Horizon: The Forbidden West' video game and the 'Jurassic World' film to 'apply' the realism of the film onto the video game scenes. The results of this project, though inconclusive, afforded me with experience in virtual machines (GoogleCloud), computer vision (image translation and style transfer), as well computer science research as a whole.
